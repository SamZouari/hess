{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.15'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.convolution import Tophat2DKernel\n",
    "from regions import CircleSkyRegion, RectangleSkyRegion\n",
    "\n",
    "from gammapy.detect import compute_lima_on_off_image,compute_lima_image # quelle différence entre les deux ?\n",
    "from gammapy.data import DataStore\n",
    "from gammapy.irf import make_mean_psf\n",
    "from gammapy.maps import Map, MapAxis, WcsGeom\n",
    "from gammapy.cube import (\n",
    "    MapDatasetMaker,\n",
    "    PSFKernel,\n",
    "    MapDataset,\n",
    "    RingBackgroundMaker,\n",
    "    SafeMaskMaker,\n",
    "    #RingBackgroundEstimator,\n",
    ")\n",
    "from gammapy.modeling.models import (\n",
    "    SkyModel,\n",
    "    SkyModels,\n",
    "    BackgroundModel,\n",
    "    PowerLawSpectralModel,\n",
    "    PowerLaw2SpectralModel,\n",
    "    PointSpatialModel,\n",
    "    ExpCutoffPowerLawSpectralModel,\n",
    "    SkyDiffuseCube,\n",
    "    TemplateSpatialModel,\n",
    "    GaussianSpatialModel\n",
    ")\n",
    "from gammapy.stats import significance, excess # utiles ?\n",
    "\n",
    "from gammapy.modeling import Fit\n",
    "from astropy.time import Time\n",
    "\n",
    "src_pos = SkyCoord(359.94, -0.04, unit=\"deg\", frame=\"galactic\")\n",
    "\n",
    "import gammapy\n",
    "gammapy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "emin, emax = [0.5, 100] * u.TeV\n",
    "\n",
    "energy_axis = MapAxis.from_bounds(\n",
    "    emin.value, emax.value, 20, unit=\"TeV\", name=\"energy\", interp=\"log\"\n",
    ")\n",
    "geom = WcsGeom.create(\n",
    "    skydir=(0, 0),\n",
    "    binsz=0.02,\n",
    "    width=(10, 8),\n",
    "    coordsys=\"GAL\",\n",
    "    proj=\"CAR\",\n",
    "    axes=[energy_axis],\n",
    ")\n",
    "\n",
    "geom2d = WcsGeom.create(\n",
    "    skydir=(0, 0),\n",
    "    binsz=0.02,\n",
    "    width=(10, 8),\n",
    "    coordsys=\"GAL\",\n",
    "    proj=\"CAR\",\n",
    ")\n",
    "\n",
    "energy_axis_true = MapAxis.from_bounds(\n",
    "    0.3, 200, 30, unit=\"TeV\", name=\"energy\", interp=\"log\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Directory for outputs\n",
    "\n",
    "path = Path(\"../../../../gammapy_data/GC_variability2020/hap-fr\")\n",
    "path.mkdir(exist_ok=True)\n",
    "\n",
    "pathma = Path(path/\"mapdatasets\")\n",
    "pathma.mkdir(exist_ok=True)\n",
    "\n",
    "pathmo = Path(path/\"models\")\n",
    "pathmo.mkdir(exist_ok=True)\n",
    "\n",
    "# for consistency we will use the template using exp cutoff for both the central source and the DE\n",
    "# but it will generally require that the cutoff of the DE be frozen and set to infinity (lambda = 0)\n",
    "\n",
    "model_name = pathmo/\"models_template_2cutoff.yaml\" \n",
    "\n",
    "pathres = Path(path/\"1cutoff_time_analysis_bis\")\n",
    "pathres.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapdataset_dict = {}\n",
    "\n",
    "for k in range (2004,2020):\n",
    "    name = \"map\" + str(k)\n",
    "    mapdataset_dict[k] = MapDataset.create(\n",
    "    geom=geom, energy_axis_true=energy_axis_true, name=name)\n",
    "\n",
    "for year in range(2004,2020):\n",
    "    \n",
    "    filename = \"mapdataset\" +str(year)+\".fits.gz\"\n",
    "    mapdataset_dict[year] = MapDataset.read(pathma/filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the model template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelGC,modelG09, modeldiff = SkyModels.read(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if needed\n",
    "modelGC.parameters[\"index\"].frozen = True\n",
    "modelGC.parameters[\"index\"].value = 1.8\n",
    "\n",
    "modeldiff.spectral_model.parameters['lambda_'].frozen = True\n",
    "modeldiff.spectral_model.parameters['lambda_'].value = 5.5\n",
    "\n",
    "modeldiff.parameters[\"index\"].frozen = True\n",
    "modeldiff.parameters[\"index\"].value = 2.3\n",
    "\n",
    "modeldiff.spectral_model.parameters['lambda_'].frozen = True\n",
    "modeldiff.spectral_model.parameters['lambda_'].value = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_region = RectangleSkyRegion(src_pos, 4*u.deg, 2*u.deg)\n",
    "\n",
    "J1745_303_region = CircleSkyRegion(SkyCoord(358.6,  -0.6, unit=\"deg\", frame=\"galactic\"), 0.5 * u.deg)\n",
    "\n",
    "fit_mask = geom.region_mask([fit_region])*geom.region_mask([J1745_303_region] , inside=False)\n",
    "\n",
    "fit_mask = Map.from_geom(geom, data=fit_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the mask and the model template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2004,2020):\n",
    "    mapdataset_dict[year].fit_mask = fit_mask\n",
    "    mapdataset_dict[year].models =  modelGC.copy() + modelG09.copy() +  modeldiff.copy()\n",
    "    mapdataset_dict[year].background_model.parameters['norm'].value = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_dataset(mapdataset):\n",
    "    fit = Fit([mapdataset])\n",
    "    result = fit.run()\n",
    "    \n",
    "    table = result.parameters.to_table()\n",
    "    \n",
    "    return table, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results_per_year = dict()\n",
    "results = []\n",
    "\n",
    "\n",
    "for year in range(2004,2020):\n",
    "    \n",
    "    table, result = fit_dataset(mapdataset_dict[year])\n",
    "    \n",
    "    results.append(result)\n",
    "    \n",
    "    results_per_year[year] = table\n",
    "    \n",
    "    mapdataset_dict[year].models[0].spectral_model.parameters.covariance = (\n",
    "    result.parameters.covariance[2:7,2:7])\n",
    "\n",
    "    # Assume the spectral model template for the DE has an exponential cutoff\n",
    "    mapdataset_dict[year].models[2].spectral_model.parameters.covariance = (\n",
    "    result.parameters.covariance[13:18,13:18])\n",
    "    \n",
    "    # mapdataset_dict[year].background_model['norm'] include the error on the normalisation\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we automatically exclude the years for which the fit didn't succeed\n",
    "\n",
    "years = []\n",
    "for year in range(2004,2020):\n",
    "    if results[year-2004].message =='Optimization terminated successfully.':\n",
    "        years.append(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of the spectral models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrum(models, path ,namefile, name):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plot_kwargs = {\n",
    "        \"energy_range\": [0.1, 30] * u.TeV,\n",
    "        \"energy_power\": 2,\n",
    "        \"flux_unit\": \"erg-1 cm-2 s-1\",\n",
    "    }\n",
    "\n",
    "    index = models[0].spectral_model.parameters[\"index\"].value\n",
    "    amp = models[0].spectral_model.parameters[\"amplitude\"].value\n",
    "    cutoff = 1/models[0].spectral_model.parameters[\"lambda_\"].value\n",
    "\n",
    "    # plot stacked model\n",
    "    models[0].spectral_model.plot(\n",
    "        **plot_kwargs, label=r\"J1745-290 : index = {0:03.3f} , amplitude = {1:03.2f}e-12 (cm^2 s TeV)^-1, cutoff = {2:03.3f} TeV\".format(index, 10**12*amp, cutoff)\n",
    "    )\n",
    "    models[0].spectral_model.plot_error(**plot_kwargs)\n",
    "\n",
    "    index = models[2].spectral_model.parameters[\"index\"].value\n",
    "    amp = models[2].spectral_model.parameters[\"amplitude\"].value\n",
    "    #cutoff = 1/models[2].spectral_model.parameters[\"lambda_\"].value\n",
    "\n",
    "    models[2].spectral_model.plot(\n",
    "        **plot_kwargs, label=r\"diffuse      : index = {0:03.3f} , amplitude = {1:03.2f}e-12 (cm^2 s TeV)^-1\".format(index, 10**12*amp, )\n",
    "    )\n",
    "    models[2].spectral_model.plot_error(**plot_kwargs)\n",
    "\n",
    "    plt.title(\"Spectral models fitted for a constant GC source (\" + name + \")\")\n",
    "    plt.legend()\n",
    "    plt.savefig(path/namefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrum(mapdataset_dict[2004].models, pathres,\"example_model_2004.pdf\", \"2004\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time evolution of the fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateFluxFromModels(mapdataset, emin, emax):\n",
    "    GC_model, G09, DE_model  = mapdataset.models\n",
    "    \n",
    "    amplitudeGC = GC_model.spectral_model.parameters['amplitude'].value\n",
    "    amp_errGC = np.sqrt(GC_model.spectral_model.parameters.covariance[1,1])\n",
    "    \n",
    "    amplitudediff = DE_model.spectral_model.parameters['amplitude'].value\n",
    "    amp_errdiff = np.sqrt(DE_model.spectral_model.parameters.covariance[1,1])\n",
    "    \n",
    "    #norm = mapdataset.background_model.parameters['norm'].value\n",
    "    #norm_err = mapdataset.background_model.parameters['norm'].error\n",
    "    \n",
    "    if isinstance(emin, u.Quantity):\n",
    "\n",
    "        diffuse_flux = DE_model.spectral_model.integral(emin, emax)\n",
    "        GC_flux = GC_model.spectral_model.integral(emin, emax)\n",
    "        \n",
    "    if np.isscalar(emin):\n",
    "        emin = emin*u.TeV\n",
    "        emax = emax*u.TeV\n",
    "        diffuse_flux = DE_model.spectral_model.integral(emin, emax)\n",
    "        GC_flux = GC_model.spectral_model.integral(emin, emax)\n",
    "\n",
    "    return diffuse_flux, GC_flux, amplitudeGC, amp_errGC, amplitudediff, amp_errdiff#, norm, norm_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def CalculateFluxFromModels_old(year, emin, emax):\n",
    "    GC_model, G09, DE_model  = mapdataset_dict[year].models\n",
    "    \n",
    "    amplitudeGC = results_per_year[year]['value'][3]\n",
    "    amp_errGC = results_per_year[year]['error'][3]\n",
    "    amplitudediff = results_per_year[year]['value'][12]\n",
    "    amp_errdiff = results_per_year[year]['error'][12]\n",
    "\n",
    "    norm = results_per_year[year]['value'][14]\n",
    "    norm_err = results_per_year[year]['error'][14]\n",
    "\n",
    "    if isinstance(emin, u.Quantity):\n",
    "        #il faut convertir le flux du diffus qui est en sr-1, \n",
    "        # donc intégrer sur tout l'angle solide du template (opération inverse de celle effectuée par TamplateSpatialModel)\n",
    "        \n",
    "        diffuse_flux = DE_model.spectral_model.integral(emin, emax)#*solid_angle_tot/u.sr  \n",
    "        GC_flux = GC_model.spectral_model.integral(emin, emax)\n",
    "        \n",
    "    if np.isscalar(emin):\n",
    "        emin = emin*u.TeV\n",
    "        emax = emax*u.TeV\n",
    "        diffuse_flux = DE_model.spectral_model.integral(emin, emax)\n",
    "        GC_flux = GC_model.spectral_model.integral(emin, emax)\n",
    "    \n",
    "    return diffuse_flux, GC_flux, amplitudeGC, amp_errGC, amplitudediff, amp_errdiff, norm, norm_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting parameters from each years fitted model\n",
    "\n",
    "emin = 1.0*u.TeV\n",
    "emax = 10*u.TeV\n",
    "resGC = []\n",
    "resdiff = []\n",
    "ampsGC = []\n",
    "amp_errsGC = []\n",
    "ampsdiff = []\n",
    "amp_errsdiff = []\n",
    "#norms = []\n",
    "#norms_err = []\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    dif , GC, amp, amp_err, ampdiff, amp_errdiff = CalculateFluxFromModels(mapdataset_dict[year], emin, emax)\n",
    "    \n",
    "    resGC.append(GC.value)\n",
    "    resdiff.append(dif.value)\n",
    "    ampsGC.append(amp)\n",
    "    amp_errsGC.append(amp_err)\n",
    "    ampsdiff.append(ampdiff)\n",
    "    amp_errsdiff.append(amp_errdiff)\n",
    "   \n",
    "    \n",
    "    #norms.append(norm)\n",
    "    #norms_err.append(norm_err)\n",
    "    \n",
    "resGC = np.asarray(resGC)\n",
    "ampsGC = np.asarray(ampsGC)\n",
    "amp_errsGC = np.asarray(amp_errsGC)\n",
    "resdiff = np.asarray(resdiff)\n",
    "ampsdiff = np.asarray(ampsdiff)\n",
    "amp_errsdiff = np.asarray(amp_errsdiff)\n",
    "#norms = np.asarray(norms)\n",
    "#norms_err = np.asarray(norms_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Errors computation\n",
    "\n",
    "yerrGC = (resGC/ampsGC)*amp_errsGC\n",
    "yerrdiff = (resdiff/ampsdiff)*amp_errsdiff\n",
    "\n",
    "cross_term = []\n",
    "\n",
    "for k,year in zip(range(len(years)),years):\n",
    "    term = 2*(cov_per_year[year][0,1]*yerrGC[k]*yerrdiff[k])/(resGC[k]*resdiff[k])\n",
    "    cross_term.append(term)\n",
    "      \n",
    "yerr_rap = (resGC/resdiff)*np.sqrt((yerrGC/resGC)**2 + (yerrdiff/resdiff)**2 - cross_term )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,15))\n",
    "\n",
    "ax1 = plt.subplot(3,1,1)\n",
    "\n",
    "plt.errorbar(years , resGC, yerr=yerrGC, fmt='ko')# ax=ax1)\n",
    "plt.title(\"Flux evolution of HESS J1745-290 (1 - 10 TeV)\")\n",
    "plt.grid()\n",
    "\n",
    "ax2 = plt.subplot(3,1,2)\n",
    "plt.errorbar(years , resdiff, yerr=yerrdiff, fmt='ko')\n",
    "plt.title(\"Flux evolution of the diffuse emission (1 - 10 TeV)\")\n",
    "plt.grid()\n",
    "\n",
    "ax2 = plt.subplot(3,1,3)\n",
    "plt.errorbar(years , resGC/resdiff, yerr=yerr_rap, fmt='ko')\n",
    "plt.title(\"Source/DE ratio evolution (1 TeV et 10 TeV)\")\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "#ax4 = plt.subplot(4,1,4)\n",
    "#plt.errorbar(years , norms, yerr=norms_err, fmt='ko')# ax=ax1)\n",
    "#plt.title(\"Background normalisation evolution\")\n",
    "#plt.grid()\n",
    "\n",
    "plt.savefig(pathres/\"GCDEflux_evolution_04_19_fr_full.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a time evolution model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "from astropy.modeling import models, fitting\n",
    "\n",
    "from scipy.stats import chisquare, chi2\n",
    "\n",
    "# chi2 non réduit\n",
    "def chisq(obs, exp, error):\n",
    "    chisq = 0\n",
    "    for i in range(len(obs)):\n",
    "        chisq = chisq + ((obs[i]-exp)**2)/(error[i]**2)\n",
    "    return chisq\n",
    "\n",
    "# chi2 réduit\n",
    "def chisqr(obs, exp, error):\n",
    "    chisqr = 0\n",
    "    for i in range(len(obs)):\n",
    "        chisqr = chisqr + ((obs[i]-exp)**2)/(error[i]**2)\n",
    "    return chisqr/(len(obs) -1)\n",
    "\n",
    "def pval(obs, exp, error, nddl): # number of DoF is the number of points minus number of fitted parameters (1 for a constant)\n",
    "    chisq = 0\n",
    "    for i in range(len(obs)):\n",
    "        chisq = chisq + ((obs[i]-exp)**2)/(error[i]**2)\n",
    "    pval = 1 - chi2.cdf(chisq, nddl)\n",
    "    return pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution for the central source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = years\n",
    "y = resGC\n",
    "y_uncs = yerrGC\n",
    "\n",
    "\n",
    "# Fit the data using a box model.\n",
    "# Bounds are not really needed but included here to demonstrate usage.\n",
    "t_init = models.Const1D(1e-12)\n",
    "fit_t = fitting.LevMarLSQFitter()\n",
    "t = fit_t(t_init, x, y) #, weights=1.0/y_uncs)\n",
    "\n",
    "# évaluation du chi2 réduit\n",
    "A1 = y\n",
    "A2 = t(2004)\n",
    "err_bars = y_uncs\n",
    "#chi2, pval = stats.chisquare(y, A2)\n",
    "#chi2r = chisqr(A1, A2, err_bars)\n",
    "\n",
    "pv = pval(A1, A2, err_bars, len(A1)-1)\n",
    "\n",
    "\n",
    "# Plot the data with the best-fit model\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(x, y, 'ko')\n",
    "plt.errorbar(x, y, yerr=y_uncs, fmt='kx', label=\"data\")\n",
    "plt.plot(x, t(x), label='constante = ' + str(round(t(2004), 14))+ \", pval = {0:0.5f}\".format(pv) )\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('Flux (1/cm²s¹)')\n",
    "plt.legend(loc=1)\n",
    "plt.title(\"Fitting of the HESS J1745-290 flux\")\n",
    "plt.savefig(pathres/\"fit_flux_SgrAstar_04_19_fr_full.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution of the diffuse emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = years\n",
    "y = resdiff\n",
    "y_uncs = yerrdiff\n",
    "\n",
    "\n",
    "# Fit the data using a box model.\n",
    "# Bounds are not really needed but included here to demonstrate usage.\n",
    "t_init = models.Const1D(1e-10)\n",
    "fit_t = fitting.LevMarLSQFitter()\n",
    "t = fit_t(t_init, x, y)#, weights=1.0/y_uncs)\n",
    "\n",
    "A1 = y\n",
    "A2 = t(2004)\n",
    "err_bars = y_uncs\n",
    "#chi2, pval = stats.chisquare(A1, A2)\n",
    "chi2r = chisqr(A1, A2, err_bars)\n",
    "\n",
    "pv = pval(A1, A2, err_bars, len(A1)-1)\n",
    "\n",
    "\n",
    "# Plot the data with the best-fit model\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(x, y, 'ko')\n",
    "plt.errorbar(x, y, yerr=y_uncs, fmt='kx', label=\"données\")\n",
    "plt.plot(x, t(x), label='constante = ' + str(round(t(2004), 14)) + \", pval = {0:0.5f}\".format(pv))\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('Flux (1/cm²s¹)')\n",
    "plt.legend(loc=1)\n",
    "plt.title(\"Fitting of the diffuse emission flux\")\n",
    "plt.savefig(pathres/\"fit_flux_DE_04_19_fr_full.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution of the ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = years\n",
    "y = resGC/resdiff\n",
    "\n",
    "\n",
    "# Fit the data using a box model.\n",
    "# Bounds are not really needed but included here to demonstrate usage.\n",
    "t_init = models.Const1D(0.6)\n",
    "fit_t = fitting.LevMarLSQFitter()\n",
    "t = fit_t(t_init, x, y, weights=1.0/y_uncs)\n",
    "\n",
    "\n",
    "A1 = y\n",
    "A2 = t(2004)\n",
    "err_bars = yerr_rap\n",
    "\n",
    "pv = pval(A1, A2, err_bars, len(A1)-1)\n",
    "\n",
    "\n",
    "# Plot the data with the best-fit model\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(x, y, 'ko')\n",
    "plt.errorbar(x, y, yerr=yerr_rap, fmt='kx', label=\"données\")\n",
    "plt.plot(x, t(x), label='constante = ' + str(round(t(2004), 3)) + \", pval = {0:0.5f}\".format(pv))\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('')\n",
    "plt.legend(loc=1)\n",
    "\n",
    "plt.title(\"Fitting of the source/DE ratio\")\n",
    "plt.savefig(pathres/\"fit_flux_GCsurDE_04_19_fr_full.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathm = Path(pathres/\"model_maps\")\n",
    "pathm.mkdir(exist_ok=True)\n",
    "\n",
    "for year in years:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    mapdataset_dict[year].npred().sum_over_axes().cutout(src_pos,3*u.deg).smooth('0.05 deg').plot()\n",
    "    plt.title(\"model prediction (npred) \" + str(year))\n",
    "    \n",
    "    name =\"model_\"+ str(year)+\"_map_fr_full.pdf\"\n",
    "    plt.savefig(pathm/name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathr = Path(pathres/\"residuals\")\n",
    "pathr.mkdir(exist_ok=True)\n",
    "\n",
    "region = CircleSkyRegion(\n",
    "    center=src_pos, radius=0.5 * u.deg\n",
    ")\n",
    "\n",
    "for year in years:\n",
    "    mapdataset_dict[year].plot_residuals(\n",
    "        region=region, method=\"diff/sqrt(model)\", vmin=-1.0, vmax=1.0\n",
    "        )\n",
    "    name = \"residuals_\"+str(year)+\"_fr_full.pdf\"\n",
    "    plt.title(\"residuals (diff/sqrt(model)) \" + str(year))\n",
    "    plt.savefig(pathr/name, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = Path(pathres/\"significance\")\n",
    "paths.mkdir(exist_ok=True)\n",
    "\n",
    "kernel = Tophat2DKernel(5) # il faut élargir la région où l'on compte les coups pour calculer la significativité, ici on prend 5 bin en distance angulaire par ex\n",
    "\n",
    "lima_significances = dict()\n",
    "\n",
    "for year in years:\n",
    "    plt.figure(figsize=(8,8))\n",
    "    counts = mapdataset_dict[year].counts.sum_over_axes()\n",
    "    mod = mapdataset_dict[year].npred().sum_over_axes()\n",
    "    lima_significances[year] = compute_lima_image(counts, mod, kernel)\n",
    "    \n",
    "    lima_significances[year]['significance'].plot()\n",
    "    name = \"significance_\"+str(year)+\"_fr_full.pdf\"\n",
    "    plt.title(\"Significance map (data v. predictions) \"+str(year))\n",
    "    plt.savefig(paths/name, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significance distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "pathh = Path(paths/\"significance_distrib\")\n",
    "pathh.mkdir(exist_ok=True)\n",
    "\n",
    "for year in years:\n",
    "    plt.figure()\n",
    "    signidata = lima_significances[year]['significance'].cutout(position=src_pos, width=(3 * u.deg, 2* u.deg)).data\n",
    "    \n",
    "    # on masque la région en bas à droite\n",
    "    mask = fit_mask.reduce_over_axes(func=np.logical_or).cutout(position=src_pos, width=(3 * u.deg, 2 * u.deg)).data\n",
    "\n",
    "    plt.hist(signidata[mask].flatten(),30, histtype='step', density=True)\n",
    "    \n",
    "    mean,std=norm.fit(signidata[mask])\n",
    "    xmin, xmax = plt.xlim()\n",
    "    x = np.linspace(xmin, xmax, 100)\n",
    "    y = norm.pdf(x, mean, std)\n",
    "    plt.plot(x, y, label=r'$\\mu$ = {0:03.4f}, $\\sigma$ = {1:03.4f}'.format(mean,std))\n",
    "    \n",
    "    plt.legend(loc=1)\n",
    "    \n",
    "    name = \"significance_hist\"+str(year)+\"_fr_full.pdf\"\n",
    "    plt.title(\"Significance distribution on the central (3°,2°) \"+str(year))\n",
    "    plt.savefig(pathh/name, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
