{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord, Angle\n",
    "from astropy.convolution import Tophat2DKernel\n",
    "from regions import CircleSkyRegion, RectangleSkyRegion\n",
    "\n",
    "from astropy.time import Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from gammapy.detect import compute_lima_on_off_image,compute_lima_image # quelle différence entre les deux ?\n",
    "\n",
    "from gammapy.data import DataStore\n",
    "from gammapy.irf import PSFKernel\n",
    "from gammapy.maps import Map, MapAxis, WcsGeom\n",
    "from gammapy.datasets import MapDataset, Datasets, FluxPointsDataset\n",
    "from gammapy.makers import (\n",
    "    MapDatasetMaker,\n",
    "    SafeMaskMaker,\n",
    "    FoVBackgroundMaker,\n",
    ")\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.modeling.models import (\n",
    "    Models,\n",
    "    SkyModel,\n",
    "    BackgroundModel,\n",
    "    PowerLawSpectralModel,\n",
    "    PowerLaw2SpectralModel,\n",
    "    PointSpatialModel,\n",
    "    ExpCutoffPowerLawSpectralModel,\n",
    "    TemplateSpatialModel,\n",
    "    GaussianSpatialModel,\n",
    "    FoVBackgroundModel\n",
    ")\n",
    "#from gammapy.stats import significance, excess # utiles ?\n",
    "from gammapy.estimators import (\n",
    "    #LiMaMapEstimator,\n",
    "    TSMapEstimator,\n",
    "    ExcessMapEstimator,\n",
    "    FluxPointsEstimator\n",
    ")\n",
    "\n",
    "\n",
    "import gammapy\n",
    "gammapy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pos = SkyCoord(359.94, -0.04, unit=\"deg\", frame=\"galactic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Directory for outputs\n",
    "\n",
    "path = Path(\"../../../hess_results/GC_variability_0.18.2/hap-fr\")\n",
    "path.mkdir(exist_ok=True)\n",
    "\n",
    "pathma = Path(path/\"mapdatasets\")\n",
    "pathma.mkdir(exist_ok=True)\n",
    "\n",
    "pathmo = Path(path/\"models\")\n",
    "pathmo.mkdir(exist_ok=True)\n",
    "\n",
    "# for consistency we will use the template using exp cutoff for both the central source and the DE\n",
    "# but it will generally require that the cutoff of the DE be frozen and set to infinity (lambda = 0)\n",
    "\n",
    "model_name = pathmo/\"models_template_2cutoff.yaml\" \n",
    "\n",
    "pathres = Path(path/\"time_analysis_alt\")\n",
    "pathres.mkdir(exist_ok=True)\n",
    "\n",
    "pathres = Path(pathres/\"all_params_free\")\n",
    "pathres.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emin, emax = [0.5, 100] * u.TeV\n",
    "\n",
    "e_bins = 20\n",
    "\n",
    "energy_axis = MapAxis.from_energy_bounds(\n",
    "    emin.value, emax.value, e_bins, unit=\"TeV\"\n",
    ")\n",
    "geom = WcsGeom.create(\n",
    "    skydir=(0, 0),\n",
    "    binsz=0.02,\n",
    "    width=(10, 8),\n",
    "    frame=\"galactic\",\n",
    "    proj=\"CAR\",\n",
    "    axes=[energy_axis],\n",
    ")\n",
    "\n",
    "geom2d = WcsGeom.create(\n",
    "    skydir=(0, 0),\n",
    "    binsz=0.02,\n",
    "    width=(10, 8),\n",
    "    frame=\"galactic\",\n",
    "    proj=\"CAR\",\n",
    ")\n",
    "\n",
    "emintrue, emaxtrue = [0.3,200] * u.TeV\n",
    "e_bins_true = 30\n",
    "\n",
    "energy_axis_true = MapAxis.from_energy_bounds(\n",
    "    emintrue.value, emaxtrue.value, e_bins_true, unit=\"TeV\", name=\"energy_true\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_year = Datasets.read(pathma/\"datasets_year.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking the datasets somehow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avant après 2014\n",
    "dataset_pre2014 = Datasets([datasets_year[f'map_{year}'] for year in range(2004,2014)]).stack_reduce()\n",
    "#dataset_pre2014.name = 'pre2014'\n",
    "dataset_post2014 = Datasets([datasets_year[f'map_{year}'] for year in range(2014,2020)]).stack_reduce()\n",
    "#dataset_post2014.name = 'post2014'\n",
    "\n",
    "\n",
    "# trois périodes pré2012, 2012-2014, post2015\n",
    "dataset_pre2012 = Datasets([datasets_year[f'map_{year}'] for year in range(2004,2012)]).stack_reduce()\n",
    "#dataset_pre2012.name = 'pre2012'\n",
    "dataset_2012_2014 = Datasets([datasets_year[f'map_{year}'] for year in range(2012,2015)]).stack_reduce()\n",
    "#dataset_2012_2014.name = '2012_2014'\n",
    "dataset_post2015 = Datasets([datasets_year[f'map_{year}'] for year in range(2015,2020)]).stack_reduce()\n",
    "#dataset_post2015.name = 'post2015'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_year = None  #to clear memory, maybe ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the model template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelGC,modelG09, modeldiff= Models.read(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if needed\n",
    "modelGC.parameters[\"amplitude\"].frozen = False\n",
    "modelGC.parameters[\"amplitude\"].value = 3.0e-12\n",
    "\n",
    "modelGC.parameters[\"index\"].frozen = False\n",
    "modelGC.parameters[\"index\"].value = 1.77\n",
    "\n",
    "modelGC.spectral_model.parameters['lambda_'].frozen = False\n",
    "modelGC.spectral_model.parameters['lambda_'].value = 1/5.4\n",
    "\n",
    "modeldiff.parameters[\"amplitude\"].frozen = False\n",
    "modeldiff.parameters[\"amplitude\"].value = 3.0e-12\n",
    "\n",
    "modeldiff.parameters[\"index\"].frozen = False\n",
    "modeldiff.parameters[\"index\"].value = 2.24\n",
    "\n",
    "modeldiff.spectral_model.parameters['lambda_'].frozen = True\n",
    "modeldiff.spectral_model.parameters['lambda_'].value = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_region = RectangleSkyRegion(src_pos, 4*u.deg, 2*u.deg)\n",
    "\n",
    "J1745_303_region = CircleSkyRegion(SkyCoord(358.6,  -0.6, unit=\"deg\", frame=\"galactic\"), 0.5 * u.deg)\n",
    "\n",
    "fit_mask = geom.region_mask([fit_region])*geom.region_mask([J1745_303_region] , inside=False)\n",
    "\n",
    "fit_mask = Map.from_geom(geom, data=fit_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the mask and the model template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pre2014.fit_mask = fit_mask\n",
    "bkg_model = FoVBackgroundModel(dataset_name = dataset_pre2014.name)\n",
    "dataset_pre2014.models =  [modelGC.copy(),modelG09.copy(),modeldiff.copy(),bkg_model]\n",
    "\n",
    "dataset_post2014.fit_mask = fit_mask\n",
    "bkg_model = FoVBackgroundModel(dataset_name = dataset_post2014.name)\n",
    "dataset_post2014.models =  [modelGC.copy(),modelG09.copy(),modeldiff.copy(),bkg_model]\n",
    "\n",
    "\n",
    "dataset_pre2012.fit_mask = fit_mask\n",
    "bkg_model = FoVBackgroundModel(dataset_name = dataset_pre2012.name)\n",
    "dataset_pre2012.models =  [modelGC.copy(),modelG09.copy(),modeldiff.copy(),bkg_model]\n",
    "\n",
    "dataset_2012_2014.fit_mask = fit_mask\n",
    "bkg_model = FoVBackgroundModel(dataset_name = dataset_2012_2014.name)\n",
    "dataset_2012_2014.models =  [modelGC.copy(),modelG09.copy(),modeldiff.copy(),bkg_model]\n",
    "\n",
    "dataset_post2015.fit_mask = fit_mask\n",
    "bkg_model = FoVBackgroundModel(dataset_name = dataset_post2015.name)\n",
    "dataset_post2015.models =  [modelGC.copy(),modelG09.copy(),modeldiff.copy(),bkg_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fit = Fit([dataset_pre2014])\n",
    "result = fit.run()\n",
    "\n",
    "fit = Fit([dataset_post2014])\n",
    "result = fit.run()\n",
    "\n",
    "fit = Fit([dataset_pre2012])\n",
    "result = fit.run()\n",
    "\n",
    "fit = Fit([dataset_2012_2014])\n",
    "result = fit.run()\n",
    "\n",
    "fit = Fit([dataset_post2015])\n",
    "result = fit.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shape of the spectral models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrum(models, path ,namefile, name):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plot_kwargs = {\n",
    "        \"energy_range\": [0.1, 30] * u.TeV,\n",
    "        \"energy_power\": 2,\n",
    "        \"flux_unit\": \"erg-1 cm-2 s-1\",\n",
    "    }\n",
    "\n",
    "    ## central source\n",
    "    index = models[0].spectral_model.parameters[\"index\"].value\n",
    "    amp = models[0].spectral_model.parameters[\"amplitude\"].value\n",
    "    \n",
    "    if models[0].spectral_model.parameters[\"lambda_\"].value != 0:\n",
    "        cutoff = 1/models[0].spectral_model.parameters[\"lambda_\"].value\n",
    "        models[0].spectral_model.plot(\n",
    "        **plot_kwargs, label=r\"HESS J175-290 : index = {0:03.3f} , amplitude = {1:03.2f}e-12 (cm^2 s TeV)^-1, cutoff = {2:03.3f} TeV\".format(index, 10**12*amp, cutoff))\n",
    "    else :  \n",
    "        models[0].spectral_model.plot(\n",
    "        **plot_kwargs, label=r\"HESS J175-290 : index = {0:03.3f} , amplitude = {1:03.2f}e-12 (cm^2 s TeV)^-1\".format(index, 10**12*amp ))\n",
    "    models[0].spectral_model.plot_error(**plot_kwargs)\n",
    "\n",
    "    \n",
    "    ## diffuse model\n",
    "    index = models[2].spectral_model.parameters[\"index\"].value\n",
    "    amp = models[2].spectral_model.parameters[\"amplitude\"].value\n",
    "    \n",
    "    if models[2].spectral_model.parameters[\"lambda_\"].value != 0:\n",
    "        cutoff = 1/models[2].spectral_model.parameters[\"lambda_\"].value\n",
    "        models[2].spectral_model.plot(\n",
    "        **plot_kwargs, label=r\"diffuse              : index = {0:03.3f} , amplitude = {1:03.2f}e-12 (cm^2 s TeV)^-1, cutoff = {2:03.3f} TeV\".format(index, 10**12*amp, cutoff ))\n",
    "    else :  \n",
    "        models[2].spectral_model.plot(\n",
    "        **plot_kwargs, label=r\"diffuse              : index = {0:03.3f} , amplitude = {1:03.2f}e-12 (cm^2 s TeV)^-1\".format(index, 10**12*amp ))\n",
    "    models[2].spectral_model.plot_error(**plot_kwargs)\n",
    "\n",
    "    plt.title(\"Spectral models fitted for a constant GC source (\" + name + \")\")\n",
    "    plt.legend()\n",
    "    plt.savefig(path/namefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrum(dataset_pre2014.models, pathres,\"pre2014_spectrum.pdf\", \"pre 2014\")\n",
    "plot_spectrum(dataset_post2014.models, pathres,\"post2014_spectrum.pdf\", \"post 2014\")\n",
    "\n",
    "plot_spectrum(dataset_pre2012.models, pathres,\"pre2012_spectrum.pdf\", \"pre 2012\")\n",
    "plot_spectrum(dataset_2012_2014.models, pathres,\"2012-2014_spectrum.pdf\", \"2012-2014\")\n",
    "plot_spectrum(dataset_post2015.models, pathres,\"post2015_spectrum.pdf\", \"post 2015\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time evolution of the fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateFluxFromModels(mapdataset, emin, emax):\n",
    "    models  = mapdataset.models\n",
    "    \n",
    "    ampGC = models[0].spectral_model.parameters['amplitude'].value\n",
    "    amp_errGC = models[0].spectral_model.parameters['amplitude'].error\n",
    "    \n",
    "    ampdiff = models[2].spectral_model.parameters['amplitude'].value\n",
    "    amp_errdiff = models[2].spectral_model.parameters['amplitude'].error\n",
    "    \n",
    "    #norm = mapdataset.background_model.parameters['norm'].value\n",
    "    #norm_err = mapdataset.background_model.parameters['norm'].error\n",
    "    \n",
    "    if isinstance(emin, u.Quantity):\n",
    "\n",
    "        diff_flux = models[2].spectral_model.integral(emin, emax)\n",
    "        GC_flux = models[0].spectral_model.integral(emin, emax)\n",
    "        \n",
    "    if np.isscalar(emin):\n",
    "        emin = emin*u.TeV\n",
    "        emax = emax*u.TeV\n",
    "        diff_flux = models[2].spectral_model.integral(emin, emax)\n",
    "        GC_flux = models[0].spectral_model.integral(emin, emax)\n",
    "        \n",
    "    fluxerrGC = (GC_flux/ampGC)*amp_errGC\n",
    "    fluxerrdiff = (diff_flux/ampdiff)*amp_errdiff\n",
    "\n",
    "    cross_term = 2*(mapdataset.models.covariance.data[1,13]*fluxerrGC*fluxerrdiff)/(GC_flux*diff_flux)\n",
    "      \n",
    "    flux_rap_err = (GC_flux/diff_flux)*np.sqrt((fluxerrGC/GC_flux)**2 + (fluxerrdiff/diff_flux)**2 - cross_term )\n",
    "\n",
    "    return GC_flux, diff_flux, GC_flux/diff_flux, fluxerrGC, fluxerrdiff, flux_rap_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emin = 1.0*u.TeV\n",
    "emax = 10*u.TeV\n",
    "\n",
    "a, b, flux_ratio, c, d, flux_rap_err = CalculateFluxFromModels(dataset_pre2014, emin, emax)\n",
    "ratio_pre2014 = [flux_ratio,flux_rap_err]\n",
    "a, b, flux_ratio, c, d, flux_rap_err = CalculateFluxFromModels(dataset_post2014, emin, emax)\n",
    "ratio_post2014 = [flux_ratio,flux_rap_err]\n",
    "\n",
    "\n",
    "a, b, flux_ratio, c, d, flux_rap_err = CalculateFluxFromModels(dataset_pre2012, emin, emax)\n",
    "ratio_pre2012 = [flux_ratio,flux_rap_err]\n",
    "a, b, flux_ratio, c, d, flux_rap_err = CalculateFluxFromModels(dataset_2012_2014, emin, emax)\n",
    "ratio_2012_2014 = [flux_ratio,flux_rap_err]\n",
    "a, b, flux_ratio, c, d, flux_rap_err = CalculateFluxFromModels(dataset_post2015, emin, emax)\n",
    "ratio_post2015 = [flux_ratio,flux_rap_err]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "présenter tout ça correctement et graphiquement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 =[2009, 2017]\n",
    "x1err = [5, 3]\n",
    "y1 = [ratio_pre2014[0],ratio_post2014[0]]\n",
    "y1err = [ratio_pre2014[1],ratio_post2014[1]]\n",
    "\n",
    "x2 =[2008.5, 2014, 2017.5]\n",
    "x2err = [4.5,1, 2.5]\n",
    "y2 = [ratio_pre2012[0],ratio_2012_2014[0], ratio_post2015[0]]\n",
    "y2err = [ratio_pre2012[1],ratio_2012_2014[1],ratio_post2015[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "\n",
    "plt.errorbar(x1, y1, xerr=x1err, yerr=y1err, fmt='ko')\n",
    "plt.title(\"Flux ratio (J1745/diffuse) evolution (1 - 10 TeV) (HAP-fr)\")\n",
    "plt.grid()\n",
    "\n",
    "ax2 = plt.subplot(2,1,2)\n",
    "plt.errorbar(x2, y2, xerr=x2err, yerr=y2err, fmt='ko')\n",
    "plt.title(\"Flux ratio (J1745/diffuse) evolution (1 - 10 TeV) (HAP-fr)\")\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(pathres/\"flux_ratio_evolution_all_params_free.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a time evolution model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "from astropy.modeling import models, fitting\n",
    "\n",
    "from scipy.stats import chisquare, chi2\n",
    "\n",
    "# chi2 non réduit\n",
    "def chisq(obs, exp, error):\n",
    "    chisq = 0\n",
    "    for i in range(len(obs)):\n",
    "        chisq = chisq + ((obs[i]-exp)**2)/(error[i]**2)\n",
    "    return chisq\n",
    "\n",
    "# chi2 réduit\n",
    "def chisqr(obs, exp, error):\n",
    "    chisqr = 0\n",
    "    for i in range(len(obs)):\n",
    "        chisqr = chisqr + ((obs[i]-exp)**2)/(error[i]**2)\n",
    "    return chisqr/(len(obs) -1)\n",
    "\n",
    "def pval(obs, exp, error, nddl): # number of DoF is the number of points minus number of fitted parameters (1 for a constant)\n",
    "    chisq = 0\n",
    "    for i in range(len(obs)):\n",
    "        chisq = chisq + ((obs[i]-exp)**2)/(error[i]**2)\n",
    "    pval = 1 - chi2.cdf(chisq, nddl)\n",
    "    return pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution of the ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [ k for k in range(2004,2020)]\n",
    "x =  np.array(x1)\n",
    "y =  np.array(y1)\n",
    "y_uncs = np.array(y1err)\n",
    "\n",
    "# Fit the data using a box model.\n",
    "# Bounds are not really needed but included here to demonstrate usage.\n",
    "t_init = models.Const1D(0.6)\n",
    "fit_t = fitting.LevMarLSQFitter()\n",
    "t = fit_t(t_init, x, y, weights=1.0/y_uncs)\n",
    "\n",
    "\n",
    "A1 = y\n",
    "A2 = t(2004)\n",
    "err_bars = y1err\n",
    "\n",
    "pv = pval(A1, A2, err_bars, len(A1)-1)\n",
    "\n",
    "error_const = np.sqrt(sum([a**2 for a in err_bars]))/len(A1)\n",
    "\n",
    "\n",
    "# Plot the data with the best-fit model\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(x, y, 'ko')\n",
    "plt.errorbar(x, y,xerr=x1err, yerr=y_uncs, fmt='kx', label=\"data\")\n",
    "plt.plot(years, t(years), label=f\"constant ratio = {A2:0.2e} ± {error_const:0.1e}, pval = {pv:0.2e}\")\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('')\n",
    "plt.legend(loc=1)\n",
    "\n",
    "plt.title(\"Fitting of the source/DE ratio\")\n",
    "plt.savefig(pathres/\"LC_ratio_2periods.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [ k for k in range(2004,2020)]\n",
    "x =  np.array(x2)\n",
    "y =  np.array(y2)\n",
    "y_uncs = np.array(y2err)\n",
    "\n",
    "# Fit the data using a box model.\n",
    "# Bounds are not really needed but included here to demonstrate usage.\n",
    "t_init = models.Const1D(0.6)\n",
    "fit_t = fitting.LevMarLSQFitter()\n",
    "t = fit_t(t_init, x, y, weights=1.0/y_uncs)\n",
    "\n",
    "\n",
    "A1 = y\n",
    "A2 = t(2004)\n",
    "err_bars = y2err\n",
    "\n",
    "pv = pval(A1, A2, err_bars, len(A1)-1)\n",
    "\n",
    "error_const = np.sqrt(sum([a**2 for a in err_bars]))/len(A1)\n",
    "\n",
    "\n",
    "# Plot the data with the best-fit model\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(x, y, 'ko')\n",
    "plt.errorbar(x, y,xerr=x2err, yerr=y_uncs, fmt='kx', label=\"data\")\n",
    "plt.plot(years, t(years), label=f\"constant ratio = {A2:0.2e} ± {error_const:0.1e}, pval = {pv:0.2e}\")\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('')\n",
    "plt.legend(loc=1)\n",
    "\n",
    "plt.title(\"Fitting of the source/DE ratio\")\n",
    "plt.savefig(pathres/\"LC_ratio_3periods.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathm = Path(pathres/\"model_maps\")\n",
    "pathm.mkdir(exist_ok=True)\n",
    "\n",
    "def model_prediction(dataset, namefile, namefig):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    dataset.npred().sum_over_axes().cutout(src_pos,3*u.deg).smooth('0.05 deg').plot()\n",
    "    plt.title(\"model prediction (npred) \" + namefig)\n",
    "    \n",
    "    name =\"model_\"+ namefile+\"_map_fr.pdf\"\n",
    "    plt.savefig(pathm/name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prediction(dataset_pre2014,\"pre2014\", \"pre 2014\")\n",
    "model_prediction(dataset_post2014, \"post2014\", \"post 2014\")\n",
    "\n",
    "model_prediction(dataset_pre2012, \"pre2012\", \"pre 2012\")\n",
    "model_prediction(dataset_2012_2014, \"2012-2014\", \"2012-2014\")\n",
    "model_prediction(dataset_post2015,\"post2015\", \"post 2015\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathr = Path(pathres/\"residuals\")\n",
    "pathr.mkdir(exist_ok=True)\n",
    "\n",
    "kwargs_spatial = {'vmin':-1, 'vmax':1 } # nécessaire ?\n",
    "\n",
    "kwargs_spectral = {'method':'diff/sqrt(model)', 'region' : CircleSkyRegion(\n",
    "    center=src_pos, radius=0.5 * u.deg\n",
    ")}\n",
    "\n",
    "def residuals(dataset, namefile, namefig):\n",
    "    dataset.plot_residuals(kwargs_spatial=kwargs_spatial, kwargs_spectral=kwargs_spectral)\n",
    "    plt.title(\"residuals (diff/sqrt(model)) \" + namefig)\n",
    "    name = \"residuals_\" + namefile +\"_fr.pdf\"\n",
    "    plt.savefig(pathr/name, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals(dataset_pre2014,\"pre2014\", \"pre 2014\")\n",
    "residuals(dataset_post2014, \"post2014\", \"post 2014\")\n",
    "\n",
    "residuals(dataset_pre2012, \"pre2012\", \"pre 2012\")\n",
    "residuals(dataset_2012_2014, \"2012-2014\", \"2012-2014\")\n",
    "residuals(dataset_post2015,\"post2015\", \"post 2015\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "paths = Path(pathres/\"significance\")\n",
    "paths.mkdir(exist_ok=True)\n",
    "pathh = Path(paths/\"significance_distrib\")\n",
    "pathh.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def significance(dataset, namefile, namefig):\n",
    "    plt.figure()\n",
    "\n",
    "    lima_estimator = ExcessMapEstimator(\"0.2 deg\", selection_optional=[] )\n",
    "    \n",
    "    res =  lima_estimator.run(dataset)\n",
    "    \n",
    "    res['sqrt_ts'].plot(add_cbar=True)\n",
    "    \n",
    "    name = \"significance_\"+namefile+\"_fr.pdf\"\n",
    "    \n",
    "    plt.title(\"Significance map (data v. predictions) \"+namefig)\n",
    "    plt.savefig(paths/name, overwrite=True)\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    signidata = res['sqrt_ts'].cutout(position=src_pos, width=(3 * u.deg, 1.5* u.deg)).data\n",
    "    \n",
    "    # on masque la région en bas à droite\n",
    "    mask = fit_mask.reduce_over_axes(func=np.logical_or).cutout(position=src_pos, width=(3 * u.deg, 1.5* u.deg)).data\n",
    "    \n",
    "    plt.hist(signidata[0,mask].flatten(),30, histtype='step', density=True)\n",
    "    \n",
    "    mean,std=norm.fit(signidata[0,mask])\n",
    "    xmin, xmax = plt.xlim()\n",
    "    x = np.linspace(xmin, xmax, 100)\n",
    "    y = norm.pdf(x, mean, std)\n",
    "    plt.plot(x, y, label=r'$\\mu$ = {0:03.4f}, $\\sigma$ = {1:03.4f}'.format(mean,std))\n",
    "    y2= norm.pdf(x, 0, 1)   \n",
    "    plt.plot(x, y2 ,label=r'$\\mu$ = 0, $\\sigma$ = 1')\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "    name = \"significance_hist\"+namefile+\"_fr.pdf\"\n",
    "    plt.title(\"Significance distribution on the central (3°,1.5°) \"+namefig)\n",
    "    plt.savefig(pathh/name, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "significance(dataset_pre2014,\"pre2014\", \"pre 2014\")\n",
    "significance(dataset_post2014, \"post2014\", \"post 2014\")\n",
    "\n",
    "significance(dataset_pre2012, \"pre2012\", \"pre 2012\")\n",
    "significance(dataset_2012_2014, \"2012-2014\", \"2012-2014\")\n",
    "significance(dataset_post2015,\"post2015\", \"post 2015\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flux points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathFP = Path(pathres/\"fluxpoints\")\n",
    "pathFP.mkdir(exist_ok=True)\n",
    "\n",
    "def FluxPointsFitting(dataset, e_edges, namefile):\n",
    "    # this function has to be given the number of the source model in case of multiple models\n",
    "    # more parameters exist to initialise the estimator\n",
    "    \n",
    "    fpe = FluxPointsEstimator( energy_edges=e_edges, source =0) \n",
    "    flux_points = fpe.run(datasets=[dataset])\n",
    "    flux_points_dataset = FluxPointsDataset(data=flux_points, models=dataset.models[0])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    flux_points_dataset.plot_fit()\n",
    "    name = \"fluxpoints_\"+namefile+\".pdf\"\n",
    "    plt.savefig(pathFP/name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_min, e_max = 0.5, 30\n",
    "e_edges = np.logspace(np.log10(e_min), np.log10(e_max), 11) * u.TeV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDU 'MASK_FIT' not found\n"
     ]
    }
   ],
   "source": [
    "FluxPointsFitting(dataset_pre2014, e_edges, \"pre2014\")\n",
    "FluxPointsFitting(dataset_post2014, e_edges, \"post2014\")\n",
    "\n",
    "FluxPointsFitting(dataset_pre2012, e_edges, \"pre2012\")\n",
    "FluxPointsFitting(dataset_2012_2014, e_edges, \"2012_2014\")\n",
    "FluxPointsFitting(dataset_post2015, e_edges, \"post2015\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
